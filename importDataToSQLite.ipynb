{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#SQLAlchemy libraries\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine # library to create the connection between DB and Python\n",
    "\n",
    "\n",
    "# Datetime libraries\n",
    "from datetime import datetime as dt, timedelta\n",
    "\n",
    "# library to read data from zipfile\n",
    "from zipfile import ZipFile as ZF\n",
    "import os\n",
    "\n",
    "# libraries to read json\n",
    "import json\n",
    "import requests\n",
    "from pandas.io.json import json_normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare global variables\n",
    "dbPath = \"trafficViolations/static/db\"\n",
    "\n",
    "dbName = \"trafficViolations.sqlite\"\n",
    "\n",
    "importDir = \"rawdata\"\n",
    "importFile = \"traffic-violations-in-usa.zip\"\n",
    "\n",
    "#columns name (after it is read onto pandas)\n",
    "df_col_names = ['DateOfStop', 'TimeOfStop', 'Agency', 'SubAgency', 'Description',\n",
    "       'Location', 'Latitude', 'Longitude', 'Accident', 'Belts',\n",
    "       'PersonalInjury', 'PropertyDamage', 'Fatal', 'CommercialLicense',\n",
    "       'HAZMAT', 'CommercialVehicle', 'Alcohol', 'WorkZone', 'State',\n",
    "       'VehicleType', 'Year', 'Make', 'Model', 'Color', 'ViolationType',\n",
    "       'Charge', 'Article', 'ContributedToAccident', 'Race', 'Gender',\n",
    "       'DriverCity', 'DriverState', 'DLState', 'ArrestType',\n",
    "       'Geolocation']\n",
    "\n",
    "violationCat = {\"Impaired\" : [\"ALCOHOL\",\"DRUGS\",\"ALCO\"],\n",
    "                \"Offense\" : [\"REGISTRATION\",\"LICENSE\",\"INSURANCE\",\"PLATE\",\"REG.PLATE\"],\n",
    "                \"Safety\":[\"UNSAFE\",\"SEATBELT\",\"HELMET\",\"EQUIP\",\"EQUIPMENT\",\"WINDSHIELD\",\"MIRRORS\",\"BRAKE\",\"INADEQUATE,INOPERATIVE\",\"OPERATING\"],\n",
    "                \"Violation\":[\"SPEEDING\",\"SPEED\",\"STOP\",\"PARKING\",\"FAILURE\",\"ELLUDE,LAMP,LAMPS\",\"DEVICE\",\"SIGNAL\",\"LIGHT\",\"LIGHTS\",\"AVOIDING\",\"AVOID\",\"INTERSECTION\"],\n",
    "                \"Distraction\":[\"HANDHELD\",\"MOBILE\",\"ELECTRONIC\",\"VIDEO\",\"EARPLUGS\",\"SOUND\",\"TEXT\",\"MSG.\"]\n",
    "                }\n",
    "\n",
    "vehicleGrp = {\n",
    "    \"Automobile\":[\"Automobile\",\"Limousine\",\"Station Wagon\"],\n",
    "\"Truck\":[\"Light Duty Truck\",\"Heavy Duty Truck\"],\n",
    "\"Motorcyle\":[\"Motorcycle\",\"Moped\"],\n",
    "\"Other\":[\"Recreational Vehicle\",\"Unknown\",\"Commercial Rig\",\"Camper\"],\n",
    "\"Bus\":[\"Transit Bus\",\"School Bus\",\"Cross Country Bus\"],\n",
    "\"FarmVehicle\":[\"Farm Vehicle\",\"Farm Equipment\"],\n",
    "\"Trailer\":[\"Utility Trailer\",\"Mobile Home\",\"Tandem Trailer\",\"Travel/Home Trailer\",\"Boat Trailer\"],\n",
    "\"RMS\":[\"Fire Vehicle\",\"Ambulance\",\"Police Vehicle\",\"Police(Emerg)\",\"Ambulance(Emerg)\",\"Ambulance(Non-Emerg)\",\"Police(Non-Emerg)\",\"Fire(Non-Emerg)\",\"Fire(Emerg)\"]\n",
    "}\n",
    "\n",
    "mnthToQtr = {1:1,2:1,3:1,4:2,5:2,6:2,7:3,8:3,9:3,10:4,11:4,12:4}\n",
    "\n",
    "# zipCode JSON file URL\n",
    "zipCd_URL = \"https://data.montgomerycountymd.gov/resource/mmib-2cgz.json\"\n",
    "\n",
    "#Police District JSON link\n",
    "police_dist_URL = \"https://data.montgomerycountymd.gov/resource/vxy6-ve2e.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Global Helper Functions ###################################\n",
    "# Function to derive Violation category based on description\n",
    "# ensure violationCat dict is declared as global variable\n",
    "def assignViolationCat(desc):\n",
    "    for key,value in violationCat.items():\n",
    "    #     print(value)\n",
    "        if any(v in desc for v in value):\n",
    "            return key\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "def getPoliceDistrict(str):\n",
    "    return(str if(str != \"H\") else \"8\")\n",
    "\n",
    "def assignVehGrp(vehType):\n",
    "    for key,value in vehicleGrp.items():\n",
    "    #     print(value)\n",
    "        if any(v in vehType for v in value):\n",
    "            return key\n",
    "    else:\n",
    "        return \"Other\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv data file and import into sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-fab1bc27f56c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read accident data from all the zip files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mviolationsDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m    \u001b[1;33m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportDir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimportFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Traffic_Violations.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_col_names\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportDir\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    223\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                        copy=copy, sort=sort)\n\u001b[0m\u001b[0;32m    226\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No objects to concatenate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Read accident data from all the zip files\n",
    "violationsDF = pd.concat(\\\n",
    "    [pd.read_csv(ZF(os.path.join(importDir,importFile)).open(\"Traffic_Violations.csv\"), low_memory=False, header = 0, names = df_col_names) \\\n",
    "     for file in os.listdir(importDir) \\\n",
    "     if file.endswith(\"zip\")], \\\n",
    "        ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'violationsDF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c717553c821e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mviolationsDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'violationsDF' is not defined"
     ]
    }
   ],
   "source": [
    "violationsDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violationsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropCols = [\"TimeOfStop\",\"Agency\",\"Location\",\"Latitude\",\"Longitude\",\"Accident\",'Belts',\"CommercialLicense\",\\\n",
    "            \"HAZMAT\",'CommercialVehicle', 'Alcohol', 'WorkZone',\"State\",\"Year\",\"Make\",\"Model\",\"Color\",\"Charge\",\\\n",
    "            \"Article\",\"Race\",'Gender',\"DriverCity\",\"DLState\",\"ArrestType\",'Geolocation']\n",
    "\n",
    "violationsDF.drop(dropCols, axis = 1, inplace = True)\n",
    "violationsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violationsDF[\"DateOfStop\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data\n",
    "# drop nas\n",
    "violationsDF = violationsDF.dropna(how = \"any\")\n",
    "violationsDF[\"DateOfStop\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_violations = violationsDF[violationsDF.duplicated()]\n",
    "violationsDF.drop_duplicates(inplace = True)\n",
    "violationsDF.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert yes and no values to boolean (0, 1)\n",
    "factorCols = ['PersonalInjury', 'PropertyDamage', 'Fatal','ContributedToAccident']\n",
    "\n",
    "for f in factorCols:\n",
    "    violationsDF[f] = violationsDF[f].map({\"Yes\" : True, \"No\" : False})\n",
    "\n",
    "violationsDF.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert Date of Stop and time of stop as Datatime objects\n",
    "violationsDF['DateOfStop'] = violationsDF['DateOfStop'].map(lambda r: dt.strptime(r, \"%m/%d/%Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violationsDF['Year'] = violationsDF['DateOfStop'].apply(lambda r: r.year)\n",
    "violationsDF['Month'] = violationsDF['DateOfStop'].apply(lambda r: r.month)\n",
    "violationsDF['Qtr'] = violationsDF['Month'].apply(lambda r : mnthToQtr[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violationsDF['ViolationCategory'] = violationsDF.Description.map(lambda r: assignViolationCat(str(r)))\n",
    "violationsDF.ViolationCategory.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violationsDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for Police District based on SubAgency for GeoJSON mapping\n",
    "violationsDF['PoliceDistrictID'] = violationsDF.SubAgency.map(lambda r : getPoliceDistrict(r[0]))\n",
    "violationsDF.PoliceDistrictID = violationsDF.PoliceDistrictID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violationsDF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violationsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out to CSV\n",
    "violationsDF.to_csv(os.path.join(importDir,\"Traffic_Violations_cleaned.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate method - without Geolocation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a col called ViolationCount to sum the total violation while grouping\n",
    "violationsDF['ViolationCount'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vehicle group reducing the vehicletype grouping\n",
    "violationsDF['VehicleGroup'] = violationsDF.VehicleType.map(lambda r : assignVehGrp(str(r)))\n",
    "violationsDF['VehicleGroup'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violationsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group the data by Year, Month, SubAgency, PoliceDistrictID, Gender, VehicleType, ViolationType,Driver State,\n",
    "# Geolocation, Violationcategory\n",
    "vDF_grp_alt = violationsDF[['SubAgency', 'PersonalInjury','PropertyDamage', 'Fatal', \\\n",
    "                        'VehicleGroup', 'ViolationType', 'ContributedToAccident', \\\n",
    "                         'Year', 'Month', 'Qtr','ViolationCategory','PoliceDistrictID', 'ViolationCount']].\\\n",
    "            groupby(['Year','Qtr','Month','SubAgency','PoliceDistrictID','ViolationType','ViolationCategory',\\\n",
    "                     'VehicleGroup']).agg(np.sum)\n",
    "\n",
    "vDF_grp_alt.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vDF_grp_alt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vDF_grp_alt.to_csv(os.path.join(importDir, \"Traffic_violations_grouped_new.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to sqlite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the table with ID column as primary key -IMPORTANT ELSE AUTOMAP_BASE will not work\n",
    "conn = sqlite3.connect(f'{dbPath}/{dbName}')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.executescript('''\n",
    "    PRAGMA foreign_keys=off;\n",
    "\n",
    "    BEGIN TRANSACTION;\n",
    "    \n",
    "    /*create a new table with the same column names and types while\n",
    "    defining a primary key for the desired column*/\n",
    "    \n",
    "    CREATE TABLE `traffic_violations` (\n",
    "    `ID` BIGINT PRIMARY KEY NOT NULL,\n",
    "     `Year` BIGINT,\n",
    "     `Qtr` BIGINT,\n",
    "     `Month` BIGINT,     \n",
    "     `SubAgency` TEXT,\n",
    "     `PoliceDistrictID` BIGINT,\n",
    "     `ViolationType` TEXT,\n",
    "     `ViolationCategory` TEXT,\n",
    "     `VehicleGroup` TEXT,\n",
    "     `PersonalInjury` FLOAT,\n",
    "     `PropertyDamage` FLOAT,\n",
    "     `Fatal` FLOAT,\n",
    "     `ContributedToAccident` FLOAT,\n",
    "     `ViolationCount` BIGINT\n",
    "    );\n",
    "\n",
    "    COMMIT TRANSACTION;\n",
    "\n",
    "    PRAGMA foreign_keys=on;''')\n",
    "\n",
    "#close out the connection\n",
    "c.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"sqlite:///{dbPath}/{dbName}\", echo = True)\n",
    "print(f\"sqlite:///{dbPath}/{dbName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vDF_grp_alt.to_sql(\"traffic_violations\", engine, if_exists = \"append\", index = True, index_label = \"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
